{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "catholic-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We implement the code from the paper \"Robustness and Reliability of Gender Bias Assessment in Word Embeddings: The Role of Base Pairs\",\n",
    "by Haiyang Zhang, Alison Sneyd and Mark Stevenson, AACL 2020\n",
    "'''\n",
    "# import packages\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string \n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affected-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We test codes with the pre-trained word embedding with google news input data presented in the paper\n",
    "'''\n",
    "\n",
    "# Load input data\n",
    "# load word pre-trained embeddings \n",
    "model = KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "model.init_sims()\n",
    "model_normed = KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "model_normed.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "appreciated-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Bolukbasi list professions\n",
    "with open('data/professions.json', 'r') as f:\n",
    "        professions = json.load(f)\n",
    "professions = [professions[i][0] for i in range(len(professions))] # list\n",
    "\n",
    "# BSRI female\n",
    "with open('data/bem_female_forms.txt', 'r') as f:\n",
    "        bem_female_forms = json.load(f)  # dictionary word:variants\n",
    "bem_female = [] # words in dict values to list\n",
    "for v in bem_female_forms.values():\n",
    "    for word in v:\n",
    "        bem_female.append(word)\n",
    "\n",
    "#  BSRI male        \n",
    "with open('data/bem_male_forms.txt', 'r') as f:\n",
    "        bem_male_forms = json.load(f)  # dictionary word:variants\n",
    "bem_male = []\n",
    "for v in bem_male_forms.values():\n",
    "    for word in v:\n",
    "        bem_male.append(word)\n",
    "        \n",
    "# Bolukbasi list of gender specific words       \n",
    "with open('data/gender_specific_full.json') as f:\n",
    "    gender_specific = json.load(f)\n",
    "\n",
    "#  Bolukbasi long list of gender pairs\n",
    "with open('data/equalize_pairs.json') as f:\n",
    "    equalize_pairs = json.load(f)\n",
    "    \n",
    "# female animals\n",
    "with open('data/frequent_female_animals.txt', 'r') as f: \n",
    "    f_animals = json.load(f) # list\n",
    "\n",
    "# male animals\n",
    "with open('data/frequent_male_animals.txt', 'r') as f:\n",
    "    m_animals = json.load(f) # list\n",
    "    \n",
    "# test analogies file\n",
    "with open(\"data/word-test.v1.txt\", 'r') as infile:\n",
    "    analogs = infile.readlines()\n",
    "        \n",
    "        \n",
    "# make list defining gender pairs\n",
    "# for measures & this list, + = female, - = male\n",
    "def_pairs = [('she','he'), ('her', 'his'), ('woman', 'man'), ('mary', 'john'),\n",
    "              ('herself', 'himself'),('daughter', 'son'), ('mother', 'father'), ('wife','husband'), \n",
    "              ('girl', 'boy'), ('female', 'male')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charitable-timeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-744567116a7a>:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  for w in model.wv.index2entity[:50000]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of limited vocabulary: 48088\n"
     ]
    }
   ],
   "source": [
    "# DEFINE REDUCED VOCBULARIES\n",
    "\n",
    "def safe_word(w):\n",
    "    # ignore words with numbers, etc.\n",
    "    # [a-zA-Z\\.'_\\- :;\\(\\)\\]] for emoticons\n",
    "    return (re.match(r\"^[a-zA-Z_]*$\", w) and len(w) < 20 and not re.match(r\"^_*$\", w))\n",
    "\n",
    "def netural_word(w):\n",
    "    # ignore words with numbers, etc.\n",
    "    # [a-zA-Z\\.'_\\- :;\\(\\)\\]] for emoticons\n",
    "    return (re.match(r\"^[a-z_]*$\", w) and len(w) < 20 and not re.match(r\"^_*$\", w))\n",
    "\n",
    "def limit_vocab(model, exclude = None):\n",
    "    vocab_limited = []\n",
    "    vocab_neutral = []\n",
    "    for w in model.wv.index2entity[:50000]: \n",
    "        if safe_word(w) == True:\n",
    "             vocab_limited.append(w)\n",
    "        if netural_word(w) == True:\n",
    "            vocab_neutral.append(w)\n",
    "        \n",
    "    if exclude:\n",
    "        vocab_neutral = list(set(vocab_neutral) - set(exclude))\n",
    "  \n",
    "\n",
    "    print(\"size of limited vocabulary:\", len(vocab_limited))\n",
    "    \n",
    "    wv_vocab = np.zeros((len(vocab_limited), 300))\n",
    "    for i,w in enumerate(vocab_limited):\n",
    "        wv_vocab[i,:] = model[w]\n",
    "    \n",
    "    wv_neutral = np.zeros((len(vocab_neutral), 300))\n",
    "    for i,w in enumerate(vocab_neutral):\n",
    "        wv_neutral[i,:] = model[w]\n",
    "        \n",
    "        \n",
    "            \n",
    "    w2i_neutral = {w: i for i, w in enumerate(vocab_neutral)}\n",
    "    i2w_neutral = {i:w for w, i in w2i_neutral.items()}\n",
    "    \n",
    "    return vocab_limited, wv_vocab, vocab_neutral, wv_neutral, w2i_neutral, i2w_neutral\n",
    "\n",
    "\n",
    "exclude_words = []\n",
    "for pair in def_pairs + equalize_pairs:\n",
    "    exclude_words.append(pair[0])\n",
    "    exclude_words.append(pair[1])\n",
    "exclude_words = list(set(exclude_words).union(set(gender_specific)))\n",
    "\n",
    "\n",
    "vocab_limited, wv_vocab, vocab_neutral, wv_neutral, w2i_neutral, i2w_neutral = limit_vocab(model_normed, exclude_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stable-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE GENDER BIAS MEASURE FUNCTIONS\n",
    "\n",
    "# Bolukbasi direct bias/ Caliskan word association with one base pair\n",
    "def bdb(word, pair):\n",
    "    word = model[word]/np.linalg.norm(model[word]) \n",
    "    pair0 = model[pair[0]]/np.linalg.norm(model[pair[0]])\n",
    "    pair1 = model[pair[1]]/np.linalg.norm(model[pair[1]])\n",
    "    db = np.dot(word, pair0-pair1)\n",
    "    return db\n",
    "\n",
    "\n",
    "# used to calculate ripa score\n",
    "def b_vec(word_pair): \n",
    "    word1 = word_pair[0]\n",
    "    word2 = word_pair[1]\n",
    "    vec = model[word1] - model[word2]\n",
    "    norm = np.linalg.norm(vec)\n",
    "    \n",
    "    return vec/norm\n",
    "\n",
    "\n",
    "# RIPA bias measure with one base pair\n",
    "def ripa1(word, bvec):\n",
    "    word_vec = model[word]\n",
    "    \n",
    "    return np.dot(word_vec, bvec)\n",
    "\n",
    "\n",
    "# NBM get gender direction with specified neutral vocab and base pair\n",
    "def compute_bias_by_projection(def_pair, vecs = wv_neutral, vocab = vocab_neutral):\n",
    "    females = vecs.dot(model_normed[def_pair[0]])\n",
    "    males = vecs.dot(model_normed[def_pair[1]])\n",
    "    d = {}\n",
    "    for w,m,f in zip(vocab, males, females):\n",
    "        d[w] = f-m\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "# NBM get neiighbours\n",
    "def topK(w, k=10):\n",
    "    \n",
    "    # extract the word vector for word w\n",
    "    # idx = w2i_limited[w]\n",
    "    # vec = wv_limited[idx, :]\n",
    "    \n",
    "    vec = model_normed[w]\n",
    "    # compute similarity of w with all words in the restricted vocabulary\n",
    "    sim = wv_neutral.dot(vec)\n",
    "    # sort similarities by descending order\n",
    "    sort_sim = (sim.argsort())[::-1]\n",
    "\n",
    "    # choose topK\n",
    "    best = sort_sim[:(k+1)]\n",
    "\n",
    "    return [i2w_neutral[i] for i in best if i2w_neutral[i]!=w]\n",
    "\n",
    "\n",
    "\n",
    "# NBM: get tuples of biases and counts of masculine/feminine NN for each word (for bias-by-neighbors)\n",
    "def bias_by_neighbors(target_words,gender_bias, neighbours_num = 100):\n",
    "    \n",
    "    tuples = []\n",
    "    neighbor_bias = {}\n",
    "    for w in target_words:\n",
    "        \n",
    "        top = topK(w, k=neighbours_num+5)[:neighbours_num]\n",
    "        \n",
    "        m = 0\n",
    "        f = 0    \n",
    "        for t in top:\n",
    "            if gender_bias[t] > 0:\n",
    "                f+=1\n",
    "            else:\n",
    "                m+=1\n",
    "        neighbor_bias[w] = (f-m)/(f+m)\n",
    "\n",
    "        tuples.append((w, m, f, (f-m)/(f+m)))\n",
    "\n",
    "    return neighbor_bias\n",
    "\n",
    "\n",
    "# make dictionary of DB/WA scores for base pair list (keys) and vocab list\n",
    "def make_bdb_scores_dict(word_pairs, word_list):\n",
    "    bdb_scores = {}\n",
    "\n",
    "    for pair in word_pairs:\n",
    "        bdb_scores[pair] = []\n",
    "\n",
    "        for word in word_list:\n",
    "            score = bdb(word, pair)\n",
    "            bdb_scores[pair].append(score)\n",
    "            \n",
    "    return bdb_scores\n",
    "\n",
    "# make dictionary of RIPA scores for base pair list (keys) and vocab list\n",
    "def make_ripa_scores_dict(word_pairs, word_list):\n",
    "    ripa_scores = {}\n",
    "\n",
    "    for pair in word_pairs:\n",
    "        ripa_scores[pair] = []\n",
    "\n",
    "        for word in word_list:\n",
    "            bvec = b_vec(pair)\n",
    "            score = ripa1(word, bvec)\n",
    "            ripa_scores[pair].append(score)\n",
    "            \n",
    "    return ripa_scores\n",
    "\n",
    "# make dictionary of NBM scores for base pair list (keys) and vocab list\n",
    "def make_nbm_scores_dict(word_pairs, word_list):\n",
    "    nbm_scores = {}\n",
    "  \n",
    "    for pair in word_pairs:\n",
    "        direct_bias = compute_bias_by_projection(pair)\n",
    "        nbm = bias_by_neighbors(word_list,direct_bias, neighbours_num = 100)\n",
    "        nbm_scores[pair]=list(nbm.values())\n",
    "\n",
    "            \n",
    "    return nbm_scores\n",
    "\n",
    "# turn bias scores to directions (male or female)\n",
    "def make_binary(df):\n",
    "    binary_df = df.copy()\n",
    "    binary_df[binary_df<0] = 0\n",
    "    binary_df[binary_df>0] = 1\n",
    "    return binary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ready-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SCORE DICTIONARIES\n",
    "bdb_profs_scores = make_bdb_scores_dict(def_pairs, professions)\n",
    "ripa_profs_scores = make_ripa_scores_dict(def_pairs, professions)\n",
    "nbm_profs_scores = make_nbm_scores_dict(def_pairs, professions)\n",
    "\n",
    "bdb_bf_scores = make_bdb_scores_dict(def_pairs, bem_female)\n",
    "bdb_bm_scores = make_bdb_scores_dict(def_pairs, bem_male)\n",
    "ripa_bf_scores = make_ripa_scores_dict(def_pairs, bem_female)\n",
    "ripa_bm_scores = make_ripa_scores_dict(def_pairs, bem_male)\n",
    "nbm_bf_scores = make_nbm_scores_dict(def_pairs, bem_female)\n",
    "nbm_bm_scores = make_nbm_scores_dict(def_pairs, bem_male)\n",
    "\n",
    "bdb_af_scores = make_bdb_scores_dict(def_pairs, f_animals)\n",
    "bdb_am_scores = make_bdb_scores_dict(def_pairs, m_animals)\n",
    "ripa_af_scores = make_ripa_scores_dict(def_pairs, f_animals)\n",
    "ripa_am_scores = make_ripa_scores_dict(def_pairs, m_animals)\n",
    "nbm_af_scores = make_nbm_scores_dict(def_pairs, f_animals)\n",
    "nbm_am_scores = make_nbm_scores_dict(def_pairs, m_animals)\n",
    "\n",
    "\n",
    "# convert dictionaries to dfs\n",
    "df_bdb_prof = pd.DataFrame.from_dict(bdb_profs_scores, orient='index', columns = professions).T\n",
    "df_ripa_prof = pd.DataFrame.from_dict(ripa_profs_scores, orient='index', columns = professions).T\n",
    "df_nbm_prof = pd.DataFrame.from_dict(nbm_profs_scores, orient='index', columns = professions).T\n",
    "\n",
    "df_bdb_bemf = pd.DataFrame.from_dict(bdb_bf_scores, orient='index', columns = bem_female).T\n",
    "df_bdb_bemm = pd.DataFrame.from_dict(bdb_bm_scores, orient='index', columns = bem_male).T\n",
    "df_ripa_bemf = pd.DataFrame.from_dict(ripa_bf_scores, orient='index', columns = bem_female).T\n",
    "df_ripa_bemm = pd.DataFrame.from_dict(ripa_bm_scores, orient='index', columns = bem_male).T\n",
    "df_nbm_bemf = pd.DataFrame.from_dict(nbm_bf_scores, orient='index', columns = bem_female).T\n",
    "df_nbm_bemm = pd.DataFrame.from_dict(nbm_bm_scores, orient='index', columns = bem_male).T\n",
    "\n",
    "df_bdb_anf = pd.DataFrame.from_dict(bdb_af_scores, orient='index', columns = f_animals).T\n",
    "df_bdb_anm = pd.DataFrame.from_dict(bdb_am_scores, orient='index', columns = m_animals).T\n",
    "df_ripa_anf = pd.DataFrame.from_dict(ripa_af_scores, orient='index', columns = f_animals).T\n",
    "df_ripa_anm = pd.DataFrame.from_dict(ripa_am_scores, orient='index', columns = m_animals).T\n",
    "df_nbm_anf = pd.DataFrame.from_dict(nbm_af_scores, orient='index', columns = f_animals).T\n",
    "df_nbm_anm = pd.DataFrame.from_dict(nbm_am_scores, orient='index', columns = m_animals).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "printable-softball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD/WA\n",
      "& 0.65  & 0.53  & 0.56  & 0.32  & 0.60  & 0.28  & 0.40  & 0.17  & 0.49  & 0.38  & 0.44 \n",
      "RIPA\n",
      "& 0.80  & 0.56  & 0.58  & 0.32  & 0.59  & 0.27  & 0.31  & 0.19  & 0.49  & 0.35  & 0.44 \n",
      "NBM\n",
      "& 0.58  & 0.65  & 0.61  & 0.19  & 0.69  & 0.18  & 0.23  & 0.14  & 0.53  & 0.18  & 0.40 \n"
     ]
    }
   ],
   "source": [
    "# DIFFERENT FORMS BASE PAIRS\n",
    "# compare profession scores with using capitalized versions of base pairs eg (she, he) vs (She, He)\n",
    "\n",
    "cap_def_pairs = [(fp.capitalize(), mp.capitalize()) for fp,mp in def_pairs]\n",
    "\n",
    "# kappa for only two classes\n",
    "def cohen_kappa(orign_df, vary_df):\n",
    "    scores = []\n",
    "    for i in range(len(orign_df.columns)):\n",
    "        pair_cohen=cohen_kappa_score(orign_df[orign_df.columns[i]], vary_df[vary_df.columns[i]])\n",
    "        scores.append(pair_cohen)\n",
    "        print('& %.2f '%(pair_cohen), end=' ')\n",
    "    print('& %.2f '%(np.mean(scores)))\n",
    "\n",
    "# make score dataframes\n",
    "bdb_profs_scores_cap = make_bdb_scores_dict(cap_def_pairs, professions)\n",
    "ripa_profs_scores_cap = make_ripa_scores_dict(cap_def_pairs, professions)\n",
    "nbm_profs_scores_cap = make_nbm_scores_dict(cap_def_pairs, professions)\n",
    "df_bdb_prof_cap = pd.DataFrame.from_dict(bdb_profs_scores_cap, orient='index', columns = professions).T\n",
    "df_ripa_prof_cap = pd.DataFrame.from_dict(ripa_profs_scores_cap, orient='index', columns = professions).T\n",
    "df_nbm_prof_cap = pd.DataFrame.from_dict(nbm_profs_scores_cap, orient='index', columns = professions).T\n",
    "\n",
    "print(\"GD/WA\")\n",
    "cohen_kappa(make_binary(df_bdb_prof),make_binary(df_bdb_prof_cap))\n",
    "print(\"RIPA\")\n",
    "cohen_kappa(make_binary(df_ripa_prof),make_binary(df_ripa_prof_cap))\n",
    "print(\"NBM\")\n",
    "cohen_kappa(make_binary(df_nbm_prof),make_binary(df_nbm_prof_cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "provincial-orbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "\n",
      "\n",
      "Base vs Capital\n",
      "DB/WA\n",
      "& 0.61  & 0.66  & 0.59  & 0.42  & 0.67  & 0.79  & 0.61  & 0.35  & 0.50  & 0.44  & 0.57 \n",
      "RIPA\n",
      "& 0.60  & 0.60  & 0.54  & 0.36  & 0.59  & 0.69  & 0.61  & 0.41  & 0.53  & 0.45  & 0.54 \n",
      "NBM\n",
      "& 0.77  & 0.63  & 0.68  & 0.54  & 0.74  & 0.68  & 0.61  & 0.32  & 0.65  & 0.63  & 0.62 \n"
     ]
    }
   ],
   "source": [
    "# PROFESSION VARIANT FORM EXPERIMENTS (PLURAL, CAPITALISED, UPPERCASE VS BASE)\n",
    "# eg compare bias direction professor to professors, Professor, PROFESSOR\n",
    "\n",
    "# define reduced professions list (whose variants are in vocab)\n",
    "professions_variants_base = []\n",
    "professions_variants_cap = []\n",
    "professions_variants_upper = []\n",
    "professions_variants_pl = []\n",
    "for prof in professions:\n",
    "    if prof.upper() in model.vocab:\n",
    "        if prof.capitalize() in model.vocab:\n",
    "            if prof+\"s\" in model.vocab:\n",
    "                professions_variants_base.append(prof)\n",
    "                professions_variants_cap.append(prof.capitalize())\n",
    "                professions_variants_upper.append(prof.upper())\n",
    "                professions_variants_pl.append(prof+\"s\")\n",
    "            elif prof+\"es\" in model.vocab:\n",
    "                professions_variants_base.append(prof)\n",
    "                professions_variants_cap.append(prof.capitalize())\n",
    "                professions_variants_upper.append(prof.upper())\n",
    "                professions_variants_pl.append(prof+\"es\")\n",
    "print(len(professions_variants_base))\n",
    "\n",
    "# base form words\n",
    "bdb_profsvb_scores = make_bdb_scores_dict(def_pairs, professions_variants_base)\n",
    "ripa_profsvb_scores = make_ripa_scores_dict(def_pairs, professions_variants_base)\n",
    "nbm_profsvb_scores = make_nbm_scores_dict(def_pairs, professions_variants_base)\n",
    "df_bdb_profvb = pd.DataFrame.from_dict(bdb_profsvb_scores, orient='index', columns = professions_variants_base).T\n",
    "df_ripa_profvb = pd.DataFrame.from_dict(ripa_profsvb_scores, orient='index', columns = professions_variants_base).T\n",
    "df_nbm_profvb = pd.DataFrame.from_dict(nbm_profsvb_scores, orient='index', columns = professions_variants_base).T\n",
    "\n",
    "# capital form words\n",
    "bdb_profscap_scores = make_bdb_scores_dict(def_pairs, professions_variants_cap)\n",
    "ripa_profscap_scores = make_ripa_scores_dict(def_pairs, professions_variants_cap)\n",
    "nbm_profscap_scores = make_nbm_scores_dict(def_pairs, professions_variants_cap)\n",
    "df_bdb_profcap = pd.DataFrame.from_dict(bdb_profscap_scores, orient='index', columns = professions_variants_base).T\n",
    "df_ripa_profcap = pd.DataFrame.from_dict(ripa_profscap_scores, orient='index', columns = professions_variants_base).T\n",
    "df_nbm_profcap = pd.DataFrame.from_dict(nbm_profscap_scores, orient='index', columns = professions_variants_base).T\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Base vs Capital\")\n",
    "print(\"DB/WA\")\n",
    "cohen_kappa(make_binary(df_bdb_profvb),make_binary(df_bdb_profcap))\n",
    "print(\"RIPA\")\n",
    "cohen_kappa(make_binary(df_ripa_profvb),make_binary(df_ripa_profcap))\n",
    "print(\"NBM\")\n",
    "cohen_kappa(make_binary(df_nbm_profvb),make_binary(df_nbm_profcap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "absent-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB/WA\n",
      "& 0.35  & 0.37  & 0.07  & -0.03  & 0.14  & 0.03  & 0.45  & 0.17  & -0.08  & 0.01  & 0.15 \n",
      "RIPA\n",
      "& 0.44  & 0.40  & 0.09  & -0.08  & 0.12  & 0.16  & 0.45  & 0.21  & -0.08  & 0.01  & 0.17 \n",
      "NBM\n",
      "& 0.27  & 0.32  & -0.01  & 0.01  & 0.27  & 0.17  & 0.46  & 0.26  & 0.18  & -0.04  & 0.19 \n"
     ]
    }
   ],
   "source": [
    "# BSRI GROUNDTRUTH VERSUS PREDICTED\n",
    "\n",
    "# varient of cohen kappa to compare df against groundtruth list\n",
    "def ground_cohen_kappa(bias_df, ground):\n",
    "    scores = []\n",
    "    for pair in bias_df.columns:\n",
    "        pair_cohen=cohen_kappa_score(ground, bias_df[pair].tolist())\n",
    "        scores.append(pair_cohen)\n",
    "        print('& %.2f '%(pair_cohen), end=' ')\n",
    "    print('& %.2f '%(np.mean(scores)))\n",
    "\n",
    "\n",
    "# define groundtruth\n",
    "ground_female = [1.0 for i in range(len(bem_female))]\n",
    "ground_male = [0.0 for i in range(len(bem_male))]\n",
    "ground = ground_female + ground_male\n",
    "\n",
    "print(\"DB/WA\")\n",
    "bdb_female_bem = make_binary(df_bdb_bemf)\n",
    "bdb_male_bem = make_binary(df_bdb_bemm)\n",
    "bdb_bem = bdb_female_bem.append(bdb_male_bem)\n",
    "ground_cohen_kappa(bdb_bem, ground)\n",
    "\n",
    "print(\"RIPA\")\n",
    "ripa_female_bem = make_binary(df_ripa_bemf)\n",
    "ripa_male_bem = make_binary(df_ripa_bemm)\n",
    "ripa_bem = ripa_female_bem.append(ripa_male_bem)\n",
    "ground_cohen_kappa(ripa_bem, ground)\n",
    "\n",
    "print(\"NBM\")\n",
    "nbm_female_bem = make_binary(df_nbm_bemf)\n",
    "nbm_male_bem = make_binary(df_nbm_bemm)\n",
    "nbm_bem = nbm_female_bem.append(nbm_male_bem)\n",
    "ground_cohen_kappa(nbm_bem, ground)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adverse-gambling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB/WA\n",
      "& 0.54  & 0.38  & 0.54  & 0.54  & 0.54  & 0.31  & 0.23  & -0.08  & 0.54  & 0.08  & 0.36 \n",
      "RIPA\n",
      "& 0.31  & 0.38  & 0.31  & 0.46  & 0.46  & 0.23  & 0.23  & 0.08  & 0.46  & 0.08  & 0.30 \n",
      "NBM\n",
      "& 0.31  & 0.08  & 0.15  & 0.15  & 0.15  & 0.00  & 0.08  & -0.08  & 0.15  & 0.00  & 0.10 \n"
     ]
    }
   ],
   "source": [
    "# ANIMAL GROUNDTRUTH VERSUS PREDICTED\n",
    "\n",
    "# define groundtruth\n",
    "ground_female = [1.0 for i in range(len(f_animals))]\n",
    "ground_male = [0.0 for i in range(len(m_animals))]\n",
    "ground = ground_female + ground_male\n",
    "\n",
    "print(\"DB/WA\")\n",
    "bdb_female_ani = make_binary(df_bdb_anf)\n",
    "bdb_male_ani = make_binary(df_bdb_anm)\n",
    "bdb_ani = bdb_female_ani.append(bdb_male_ani)\n",
    "ground_cohen_kappa(bdb_ani, ground)\n",
    "\n",
    "print(\"RIPA\")\n",
    "ripa_female_ani = make_binary(df_ripa_anf)\n",
    "ripa_male_ani = make_binary(df_ripa_anm)\n",
    "ripa_ani = ripa_female_ani.append(ripa_male_ani)\n",
    "ground_cohen_kappa(ripa_ani, ground)\n",
    "\n",
    "\n",
    "print(\"NBM\")\n",
    "nbm_female_ani = make_binary(df_nbm_anf)\n",
    "nbm_male_ani = make_binary(df_nbm_anm)\n",
    "nbm_ani = nbm_female_ani.append(nbm_male_ani)\n",
    "ground_cohen_kappa(nbm_ani, ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-release",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
